{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c820323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c774b778",
   "metadata": {},
   "source": [
    "# UDA-Bench Query Generation System\n",
    "\n",
    "This notebook implements an automated query generation system for UDA-Bench with 5 main categories:\n",
    "1. **Select**: Extract operations only\n",
    "2. **Filter**: Extract + Filter operations (6 subcategories)\n",
    "3. **Join**: Extract + Join operations (binary and multi-table)\n",
    "4. **Agg**: Extract + Aggregation operations\n",
    "5. **Mixed**: Combination of multiple operators (32 subcategories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb90125",
   "metadata": {},
   "source": [
    "First, we need define \n",
    "\n",
    "1. the attribute type, which could varies from str,int,float by its value.\n",
    "2. the specific usage of attribute, such as categoried attributes for group by, numerical attributes for count,avg etc.\n",
    "3. the source of this attribute, such as text, images ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b5432f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeType(Enum):\n",
    "    \"\"\"Attribute value types\"\"\"\n",
    "    STRING = \"str\"\n",
    "    INTEGER = \"int\"\n",
    "    FLOAT = \"float\"\n",
    "    BOOLEAN = \"bool\"\n",
    "\n",
    "\n",
    "class AttributeUsage(Enum):\n",
    "    \"\"\"Specific usage of attribute in queries\"\"\"\n",
    "    CATEGORICAL = \"categorical\"    # For GROUP BY, categorical filters\n",
    "    NUMERICAL = \"numerical\"        # For COUNT, SUM, AVG, MIN, MAX, numerical comparisons\n",
    "    GENERAL = \"general\"            # For all usage\n",
    "\n",
    "\n",
    "class AttributeModality(Enum):\n",
    "    \"\"\"Source modality of the attribute\"\"\"\n",
    "    TEXT = \"text\"           # Plain text data\n",
    "    IMAGE = \"image\"         # Image data (e.g., X-ray, photos)\n",
    "    TABLE = \"table\"         # Table data\n",
    "    STRUCTURED = \"structured\"  # Structured data from database\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Attribute:\n",
    "    \"\"\"\n",
    "    Represents a database attribute with rich metadata.\n",
    "    \n",
    "    Attributes:\n",
    "        name: Name of the attribute (column name)\n",
    "        table: Table this attribute belongs to\n",
    "        value_type: Data type of the attribute values (str, int, float, bool)\n",
    "        usage: How this attribute is typically used in queries\n",
    "        modality: Source modality of the data (text, image, table, etc.)\n",
    "        is_nullable: Whether this attribute can have NULL values\n",
    "        description: Optional description of the attribute\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    table: str\n",
    "    value_type: AttributeType\n",
    "    usage: AttributeUsage\n",
    "    modality: AttributeModality\n",
    "    is_nullable: bool = False\n",
    "    description: str = \"\"\n",
    "    \n",
    "    @property\n",
    "    def full_name(self) -> str:\n",
    "        \"\"\"Return fully qualified name: table.attribute\"\"\"\n",
    "        return f\"{self.table}.{self.name}\"\n",
    "\n",
    "    def attribute_name(self) -> str:\n",
    "        \"\"\"Return the name of the attribute\"\"\"\n",
    "        return self.name\n",
    "    \n",
    "    def is_groupable(self) -> bool:\n",
    "        \"\"\"Check if attribute can be used in GROUP BY\"\"\"\n",
    "        return self.usage in [AttributeUsage.CATEGORICAL]\n",
    "    \n",
    "    def is_aggregatable(self) -> bool:\n",
    "        \"\"\"Check if attribute can be used with aggregation functions\"\"\"\n",
    "        return self.usage == AttributeUsage.NUMERICAL\n",
    "    \n",
    "    def is_joinable(self) -> bool:\n",
    "        \"\"\"Check if attribute can be used as join key\"\"\"\n",
    "        return self.usage == AttributeUsage.IDENTIFIER\n",
    "    \n",
    "    def supports_comparison(self) -> bool:\n",
    "        \"\"\"Check if attribute supports comparison operators (<, >, =, etc.)\"\"\"\n",
    "        return self.value_type in [AttributeType.INTEGER, AttributeType.FLOAT, AttributeType.STRING]\n",
    "    \n",
    "    def supports_like(self) -> bool:\n",
    "        \"\"\"Check if attribute supports LIKE operator\"\"\"\n",
    "        return self.value_type == AttributeType.STRING\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc4e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the /data/dengqiyan/UDA-Bench/Query/Art/Art_attributes.json and to form list[Attribute]\n",
    "\n",
    "def load_attributes_from_json(json_path: str) -> List[Attribute]:\n",
    "    \"\"\"\n",
    "    Load attributes from a JSON file and convert them to Attribute objects.\n",
    "    \n",
    "    Args:\n",
    "        json_path: Path to the JSON file containing attribute definitions\n",
    "    \n",
    "    Returns:\n",
    "        List of Attribute objects\n",
    "    \"\"\"\n",
    "    # Mapping from string values to Enum types\n",
    "    type_mapping = {\n",
    "        \"str\": AttributeType.STRING,\n",
    "        \"int\": AttributeType.INTEGER,\n",
    "        \"float\": AttributeType.FLOAT,\n",
    "        \"bool\": AttributeType.BOOLEAN\n",
    "    }\n",
    "    \n",
    "    usage_mapping = {\n",
    "        \"categorical\": AttributeUsage.CATEGORICAL,\n",
    "        \"numerical\": AttributeUsage.NUMERICAL,\n",
    "        \"general\": AttributeUsage.GENERAL\n",
    "    }\n",
    "    \n",
    "    modality_mapping = {\n",
    "        \"text\": AttributeModality.TEXT,\n",
    "        \"image\": AttributeModality.IMAGE,\n",
    "        \"table\": AttributeModality.TABLE,\n",
    "        \"structured\": AttributeModality.STRUCTURED\n",
    "    }\n",
    "    \n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    attributes = []\n",
    "    \n",
    "    # Handle both flat list and nested dict formats\n",
    "    if isinstance(data, dict):\n",
    "        # Nested format: {\"Wiki_Text\": [...], \"Wiki_Art\": [...]}\n",
    "        for source_key, attr_list in data.items():\n",
    "            for attr_dict in attr_list:\n",
    "                attr = Attribute(\n",
    "                    name=attr_dict[\"name\"],\n",
    "                    table=attr_dict[\"table\"],\n",
    "                    value_type=type_mapping.get(attr_dict[\"value_type\"], AttributeType.STRING),\n",
    "                    usage=usage_mapping.get(attr_dict[\"usage\"], AttributeUsage.GENERAL),\n",
    "                    modality=modality_mapping.get(attr_dict[\"modality\"], AttributeModality.TEXT),\n",
    "                    is_nullable=attr_dict.get(\"is_nullable\", False),\n",
    "                    description=attr_dict.get(\"description\", \"\")\n",
    "                )\n",
    "                attributes.append(attr)\n",
    "    elif isinstance(data, list):\n",
    "        # Flat format: [...]\n",
    "        for attr_dict in data:\n",
    "            attr = Attribute(\n",
    "                name=attr_dict[\"name\"],\n",
    "                table=attr_dict[\"table\"],\n",
    "                value_type=type_mapping.get(attr_dict[\"value_type\"], AttributeType.STRING),\n",
    "                usage=usage_mapping.get(attr_dict[\"usage\"], AttributeUsage.GENERAL),\n",
    "                modality=modality_mapping.get(attr_dict[\"modality\"], AttributeModality.TEXT),\n",
    "                is_nullable=attr_dict.get(\"is_nullable\", False),\n",
    "                description=attr_dict.get(\"description\", \"\")\n",
    "            )\n",
    "            attributes.append(attr)\n",
    "    \n",
    "    return attributes\n",
    "\n",
    "\n",
    "# Load Art attributes\n",
    "attributes_path = \"/data/dengqiyan/UDA-Bench/Query/Player/Player_attributes.json\"\n",
    "attributes: List[Attribute] = load_attributes_from_json(attributes_path)\n",
    "\n",
    "\n",
    "# Group by modality\n",
    "text_attrs = [a for a in attributes if a.modality == AttributeModality.TEXT]\n",
    "image_attrs = [a for a in attributes if a.modality == AttributeModality.IMAGE]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc78b6c",
   "metadata": {},
   "source": [
    "## Select Templates\n",
    "\n",
    "In this cell, it is a function that recieve the avaliable attributes, which is a list like list:class Attribute, and a table name, then  populate the placeholder with the random avaliable attributes, but if exists an atribute with AttributeModality.IMAGE, then must be concluded one image attribute. The template is as \"SELECT {attribute(s)} FROM {table}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62ab41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example SELECT queries:\n",
      "--------------------------------------------------\n",
      "\n",
      "Query 1: SELECT birth_date, olympic_gold_medals FROM Art;\n",
      "  Selected attributes: ['birth_date', 'olympic_gold_medals']\n",
      "  Modalities: ['text', 'text']\n",
      "\n",
      "Query 2: SELECT NBA_team, nationality FROM Art;\n",
      "  Selected attributes: ['NBA_team', 'nationality']\n",
      "  Modalities: ['text', 'text']\n",
      "\n",
      "Query 3: SELECT founded_year, college FROM Art;\n",
      "  Selected attributes: ['founded_year', 'college']\n",
      "  Modalities: ['text', 'text']\n"
     ]
    }
   ],
   "source": [
    "def generate_select_query(attributes: List[Attribute], \n",
    "                          table: str, \n",
    "                          attribute_num: int = 1,\n",
    "                          image_num: int = 1,\n",
    "                          seed: int = None) -> Tuple[str, List[Attribute]]:\n",
    "    \"\"\"\n",
    "    Generate a SELECT query by populating placeholders with random attributes.\n",
    "    \n",
    "    If any IMAGE modality attribute exists in the available attributes,\n",
    "    at least one image attribute MUST be included in the selection.\n",
    "    \n",
    "    Args:\n",
    "        attributes: List of available Attribute objects\n",
    "        table: Table name for the FROM clause\n",
    "        min_attrs: Minimum number of attributes to select (default: 1)\n",
    "        max_attrs: Maximum number of attributes to select (default: all)\n",
    "        seed: Random seed for reproducibility (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (SQL query string, list of selected attributes)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    if not attributes:\n",
    "        raise ValueError(\"Attribute list cannot be empty\")\n",
    "    \n",
    "    \n",
    "    # Separate image attributes from non-image attributes\n",
    "    image_attrs = [attr for attr in attributes if attr.modality == AttributeModality.IMAGE]\n",
    "    non_image_attrs = [attr for attr in attributes if attr.modality != AttributeModality.IMAGE]\n",
    "    \n",
    "    selected_attrs = []\n",
    "    \n",
    "    # If image attributes exist, must include at least one\n",
    "    if image_attrs:\n",
    "        # Select at least one image attribute\n",
    "        # num_image_to_select = random.randint(1, min(len(image_attrs), max_attrs))\n",
    "        selected_image_attrs = random.sample(image_attrs, image_num)\n",
    "        selected_attrs.extend(selected_image_attrs)\n",
    "    \n",
    "    # Calculate remaining slots for non-image attributes\n",
    "    remaining_slots = attribute_num - image_num\n",
    "    \n",
    "    # Fill remaining slots with non-image attributes\n",
    "    if non_image_attrs and remaining_slots > 0:\n",
    "        num_non_image = min(remaining_slots, len(non_image_attrs))\n",
    "        selected_non_image_attrs = random.sample(non_image_attrs, num_non_image)\n",
    "        selected_attrs.extend(selected_non_image_attrs)\n",
    "    \n",
    "    # Shuffle to randomize order\n",
    "    random.shuffle(selected_attrs)\n",
    "    \n",
    "    # Build the SELECT clause\n",
    "    attribute_names = \", \".join([attr.name for attr in selected_attrs])\n",
    "    \n",
    "    # Generate the SQL query\n",
    "    sql_query = f\"SELECT {attribute_names} FROM {table};\"\n",
    "    \n",
    "    return sql_query, selected_attrs\n",
    "\n",
    "\n",
    "\n",
    "# Generate a few example queries\n",
    "print(\"Example SELECT queries:\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(3):\n",
    "    query, selected = generate_select_query(attributes, \"Art\", attribute_num=3, image_num=1)\n",
    "    print(f\"\\nQuery {i+1}: {query}\")\n",
    "    print(f\"  Selected attributes: {[attr.name for attr in selected]}\")\n",
    "    print(f\"  Modalities: {[attr.modality.value for attr in selected]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84157583",
   "metadata": {},
   "source": [
    "## Filter Templates\n",
    "\n",
    "template: SELECT {attribute(s)} From {table} WHERE subcategories.\n",
    "\n",
    "subcategory 1 : WHERE \\{Attribute\\}\\{Operator\\}\\{Literal\\}\n",
    "\n",
    "subcategory 2 : WHERE two filters with AND :  \\{Attribute\\}\\{Operator\\}\\{Literal\\} AND \\{Attribute\\}\\{Operator\\}\\{Literal\\}\n",
    "\n",
    "subcategory 3 : WHERE two filters with OR: \\{Attribute\\}\\{Operator\\}\\{Literal\\} OR \\{Attribute\\}\\{Operator\\}\\{Literal\\}\n",
    "\n",
    "subcategory 4 : WHERE three and more filters \\{Attribute\\}\\{Operator\\}\\{Literal\\} (AND \\{Attribute\\}\\{Operator\\}\\{Literal\\})^n\n",
    "\n",
    "subcategory 5 : WHERE three and more filters \\{Attribute\\}\\{Operator\\}\\{Literal\\} (OR \\{Attribute\\}\\{Operator\\}\\{Literal\\})^n\n",
    "\n",
    "subcategory 6 : WHERE three and more filters with AND OR combination\n",
    "\n",
    "\n",
    "we further classify it by the number of filters (one filter, two filters, and more than two filters) and the way of combining the filters  (conjunction only, disjunction only, and conjunction of disjunctions), resulting in a total of 6 \\texttt{Filter} sub-categories.  With varying complexities, these sub-categories of queries offer a large space for cost optimization (e.g., more filters bring a large optimization opportunity for filter reordering). \n",
    "\n",
    "As shown in the example, the pattern ``\\{Attribute\\}\\{Operator\\}\\{Literal\\}'' serves as the placeholder format for filter predicates. During query generation, we randomly sample both the filter attribute and the comparison operator (such as $\\leq$, $=$, or $\\geq$) with equal probability, and we further sample literal values to produce varying selectivities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e38a426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 141 rows from Art_Groud_Truth.csv\n",
      "ðŸ“Š Analyzed 14 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class DataStatistics:\n",
    "    \"\"\"\n",
    "    Class to load ground truth data and compute statistics for realistic literal generation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, csv_path: str):\n",
    "        \"\"\"\n",
    "        Load CSV data and compute statistics for each column.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the ground truth CSV file\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.total_rows = len(self.df)\n",
    "        self.column_stats = {}\n",
    "        self._compute_statistics()\n",
    "    \n",
    "    def _compute_statistics(self):\n",
    "        \"\"\"Compute value distribution statistics for each column.\"\"\"\n",
    "        # Define columns that use || as multi-value separator\n",
    "        MULTI_VALUE_SEPARATOR = '||'\n",
    "        \n",
    "        for col in self.df.columns:\n",
    "            # Skip non-filterable columns\n",
    "            if col in ['id', 'Artwork_URL', 'intro_url']:\n",
    "                continue\n",
    "            \n",
    "            values = self.df[col].dropna()\n",
    "            \n",
    "            if len(values) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Determine column type\n",
    "            if pd.api.types.is_numeric_dtype(values):\n",
    "                self.column_stats[col] = {\n",
    "                    'type': 'numeric',\n",
    "                    'is_multi_value': False,\n",
    "                    'min': float(values.min()),\n",
    "                    'max': float(values.max()),\n",
    "                    'mean': float(values.mean()),\n",
    "                    'median': float(values.median()),\n",
    "                    'percentiles': {\n",
    "                        10: float(values.quantile(0.1)),\n",
    "                        25: float(values.quantile(0.25)),\n",
    "                        50: float(values.quantile(0.5)),\n",
    "                        75: float(values.quantile(0.75)),\n",
    "                        90: float(values.quantile(0.9))\n",
    "                    },\n",
    "                    'values': sorted(values.unique().tolist())\n",
    "                }\n",
    "            else:\n",
    "                # String/categorical column - check for multi-value attributes\n",
    "                str_values = values.astype(str)\n",
    "                \n",
    "                # Check if this column contains multi-value entries (using ||)\n",
    "                has_multi_value = str_values.str.contains(r'\\|\\|', regex=True).any()\n",
    "                \n",
    "                if has_multi_value:\n",
    "                    # Split multi-value entries and count individual values\n",
    "                    all_individual_values = []\n",
    "                    for val in str_values:\n",
    "                        # Split by || and strip whitespace\n",
    "                        parts = [p.strip() for p in val.split(MULTI_VALUE_SEPARATOR)]\n",
    "                        all_individual_values.extend(parts)\n",
    "                    \n",
    "                    value_counts = Counter(all_individual_values)\n",
    "                else:\n",
    "                    # Single value column\n",
    "                    value_counts = Counter(str_values)\n",
    "                \n",
    "                sorted_by_freq = sorted(value_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "                \n",
    "                self.column_stats[col] = {\n",
    "                    'type': 'categorical',\n",
    "                    'is_multi_value': has_multi_value,\n",
    "                    'unique_count': len(value_counts),\n",
    "                    'value_counts': dict(sorted_by_freq),\n",
    "                    # High frequency values (common, high selectivity)\n",
    "                    'high_freq_values': [v for v, c in sorted_by_freq[:10]],\n",
    "                    # Medium frequency values\n",
    "                    'medium_freq_values': [v for v, c in sorted_by_freq[10:30] if c > 1],\n",
    "                    # Low frequency values (rare, low selectivity)\n",
    "                    'low_freq_values': [v for v, c in sorted_by_freq if c <= 2][:20],\n",
    "                    'all_values': list(value_counts.keys())\n",
    "                }\n",
    "    \n",
    "    def get_literal_by_selectivity(self, attr_name: str, selectivity: str = \"medium\") -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        Get a literal value based on the desired selectivity.\n",
    "        \n",
    "        Args:\n",
    "            attr_name: Name of the attribute (must match column name, case-insensitive)\n",
    "            selectivity: 'low' (rare values, few results), \n",
    "                        'medium' (moderate frequency),\n",
    "                        'high' (common values, many results)\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (literal_value, estimated_selectivity_ratio)\n",
    "        \"\"\"\n",
    "        # Find matching column (case-insensitive)\n",
    "        col_name = None\n",
    "        for col in self.column_stats.keys():\n",
    "            if col.lower() == attr_name.lower():\n",
    "                col_name = col\n",
    "                break\n",
    "        \n",
    "        if col_name is None:\n",
    "            # Fallback to default values\n",
    "            return \"'unknown'\", 0.0\n",
    "        \n",
    "        stats = self.column_stats[col_name]\n",
    "        \n",
    "        if stats['type'] == 'numeric':\n",
    "            return self._get_numeric_literal(stats, selectivity)\n",
    "        else:\n",
    "            return self._get_categorical_literal(stats, selectivity)\n",
    "    \n",
    "    def _get_numeric_literal(self, stats: Dict, selectivity: str) -> Tuple[str, float]:\n",
    "        \"\"\"Generate numeric literal based on selectivity using percentiles.\"\"\"\n",
    "        percentiles = stats['percentiles']\n",
    "        \n",
    "        if selectivity == \"low\":\n",
    "            # Use extreme values (top 10%) - fewer results when using < or >\n",
    "            value = percentiles[90]\n",
    "            ratio = 0.1\n",
    "        elif selectivity == \"high\":\n",
    "            # Use values around median - more results\n",
    "            value = percentiles[50]\n",
    "            ratio = 0.5\n",
    "        else:  # medium\n",
    "            # Use 25th or 75th percentile\n",
    "            value = random.choice([percentiles[25], percentiles[75]])\n",
    "            ratio = 0.25\n",
    "        \n",
    "        # Round to integer if all values are integers\n",
    "        if all(isinstance(v, int) or (isinstance(v, float) and v.is_integer()) \n",
    "               for v in stats['values'][:10]):\n",
    "            return str(int(value)), ratio\n",
    "        else:\n",
    "            return f\"{value:.2f}\", ratio\n",
    "    \n",
    "    def _get_categorical_literal(self, stats: Dict, selectivity: str) -> Tuple[str, float]:\n",
    "        \"\"\"Generate categorical literal based on selectivity using frequency.\"\"\"\n",
    "        value_counts = stats['value_counts']\n",
    "        total = sum(value_counts.values())\n",
    "        \n",
    "        if selectivity == \"low\":\n",
    "            # Pick rare values (low frequency)\n",
    "            candidates = stats['low_freq_values']\n",
    "            if not candidates:\n",
    "                candidates = stats['all_values'][-10:]  # Last 10 values\n",
    "        elif selectivity == \"high\":\n",
    "            # Pick common values (high frequency)\n",
    "            candidates = stats['high_freq_values']\n",
    "        else:  # medium\n",
    "            candidates = stats['medium_freq_values']\n",
    "            if not candidates:\n",
    "                candidates = stats['all_values']\n",
    "        \n",
    "        if not candidates:\n",
    "            candidates = stats['all_values']\n",
    "        \n",
    "        value = random.choice(candidates)\n",
    "        count = value_counts.get(value, 1)\n",
    "        ratio = count / total\n",
    "        \n",
    "        # Escape single quotes in value\n",
    "        escaped_value = value.replace(\"'\", \"''\")\n",
    "        return f\"'{escaped_value}'\", ratio\n",
    "    \n",
    "    def get_column_info(self, col_name: str) -> Dict:\n",
    "        \"\"\"Get statistics for a specific column.\"\"\"\n",
    "        for col in self.column_stats.keys():\n",
    "            if col.lower() == col_name.lower():\n",
    "                return self.column_stats[col]\n",
    "        return None\n",
    "\n",
    "\n",
    "# Load ground truth data\n",
    "gt_data_path = \"/data/dengqiyan/UDA-Bench/Query/Player/player.csv\"\n",
    "data_stats = DataStatistics(gt_data_path)\n",
    "\n",
    "# Print summary of loaded data\n",
    "print(f\"âœ… Loaded {data_stats.total_rows} rows from Art_Groud_Truth.csv\")\n",
    "print(f\"ðŸ“Š Analyzed {len(data_stats.column_stats)} columns\")\n",
    "\n",
    "# Show multi-value columns\n",
    "multi_value_cols = [col for col, stats in data_stats.column_stats.items() \n",
    "                    if stats.get('is_multi_value', False)]\n",
    "# print(f\"\\nðŸ”— Multi-value columns (using || separator): {multi_value_cols}\")\n",
    "\n",
    "# print(\"\\nColumn Statistics Summary:\")\n",
    "# print(\"-\" * 70)\n",
    "\n",
    "# for col, stats in list(data_stats.column_stats.items()):\n",
    "#     if stats['type'] == 'numeric':\n",
    "#         print(f\"  ðŸ“ˆ {col}: numeric, range=[{stats['min']:.0f}, {stats['max']:.0f}]\")\n",
    "#     else:\n",
    "#         multi_flag = \" [MULTI-VALUE]\" if stats.get('is_multi_value') else \"\"\n",
    "#         print(f\"  ðŸ“‹ {col}: categorical, {stats['unique_count']} unique values{multi_flag}\")\n",
    "#         if stats['high_freq_values']:\n",
    "#             # Show individual values (not combined with ||)\n",
    "#             print(f\"      Top values: {stats['high_freq_values'][:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a1cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FILTER QUERY EXAMPLES (6 Subcategories) - Using Real Data\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Subcategory 1: Single Filter\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "SQL: SELECT draft_year, team_name FROM Art WHERE mvp_awards = 0;\n",
      "  Combination: single\n",
      "  Num Filters: 1\n",
      "  Predicates:\n",
      "    â€¢ mvp_awards = 0  (selectivity: 50.0%)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Subcategory 2: Two Filters (AND)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "SQL: SELECT birth_date, draft_year FROM Art WHERE college LIKE 'University of Florida' AND area = '%keyword%';\n",
      "  Combination: AND\n",
      "  Num Filters: 2\n",
      "  Predicates:\n",
      "    â€¢ college LIKE 'University of Florida'  (selectivity: 1.5%)\n",
      "    â€¢ area = '%keyword%'  (selectivity: 10.0%)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Subcategory 3: Two Filters (OR)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "SQL: SELECT name, draft_year FROM Art WHERE ownership LIKE 'prefix%' OR own_year != 'exact_match';\n",
      "  Combination: OR\n",
      "  Num Filters: 2\n",
      "  Predicates:\n",
      "    â€¢ ownership LIKE 'prefix%'  (selectivity: 10.0%)\n",
      "    â€¢ own_year != 'exact_match'  (selectivity: 10.0%)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Subcategory 4: Multiple Filters (AND)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "SQL: SELECT gdp, nationality FROM Art WHERE college LIKE 'University of Kentucky' AND population = '%keyword%' AND draft_year = 1990 AND college LIKE 'UCLA  ';\n",
      "  Combination: AND\n",
      "  Num Filters: 4\n",
      "  Predicates:\n",
      "    â€¢ college LIKE 'University of Kentucky'  (selectivity: 1.5%)\n",
      "    â€¢ population = '%keyword%'  (selectivity: 10.0%)\n",
      "    â€¢ draft_year = 1990  (selectivity: 50.0%)\n",
      "    â€¢ college LIKE 'UCLA  '  (selectivity: 2.3%)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Subcategory 5: Multiple Filters (OR)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "SQL: SELECT founded_year, state_name FROM Art WHERE population != '%keyword%' OR nba_championships <= 0 OR own_year LIKE 'prefix%' OR olympic_gold_medals != 0;\n",
      "  Combination: OR\n",
      "  Num Filters: 4\n",
      "  Predicates:\n",
      "    â€¢ population != '%keyword%'  (selectivity: 10.0%)\n",
      "    â€¢ nba_championships <= 0  (selectivity: 25.0%)\n",
      "    â€¢ own_year LIKE 'prefix%'  (selectivity: 10.0%)\n",
      "    â€¢ olympic_gold_medals != 0  (selectivity: 50.0%)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Subcategory 6: Mixed AND/OR Combination\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "SQL: SELECT age, position FROM Art WHERE (nationality = 'American-born naturalized Azerbaijani  ' AND draft_year <= 2017) OR (draft_pick > 35 AND state_name = '%keyword%');\n",
      "  Combination: AND_OR_mixed\n",
      "  Num Filters: 4\n",
      "  Predicates:\n",
      "    â€¢ nationality = 'American-born naturalized Azerbaijani  '  (selectivity: 0.7%)\n",
      "    â€¢ draft_year <= 2017  (selectivity: 10.0%)\n",
      "    â€¢ draft_pick > 35  (selectivity: 10.0%)\n",
      "    â€¢ state_name = '%keyword%'  (selectivity: 10.0%)\n"
     ]
    }
   ],
   "source": [
    "# Comparison operators for different attribute types\n",
    "NUMERIC_OPERATORS = ['=', '!=', '<', '<=', '>', '>=']\n",
    "STRING_OPERATORS = ['=', '!=', 'LIKE']\n",
    "CATEGORICAL_OPERATORS = ['=', '!=', 'IN']\n",
    "\n",
    "\n",
    "def generate_literal(attr: Attribute, selectivity: str = \"medium\", \n",
    "                     stats: DataStatistics = None) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Generate a literal value for a given attribute based on real data statistics.\n",
    "    \n",
    "    Args:\n",
    "        attr: The attribute to generate a literal for\n",
    "        selectivity: 'low' (rare values, fewer results), \n",
    "                    'medium' (moderate frequency),\n",
    "                    'high' (common values, more results)\n",
    "        stats: DataStatistics object with real data (uses global data_stats if None)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (literal_value_string, selectivity_ratio)\n",
    "    \"\"\"\n",
    "    if stats is None:\n",
    "        stats = data_stats\n",
    "    \n",
    "    # Try to get literal from real data\n",
    "    literal, ratio = stats.get_literal_by_selectivity(attr.name, selectivity)\n",
    "    \n",
    "    if literal != \"'unknown'\":\n",
    "        return literal, ratio\n",
    "    \n",
    "    # Fallback to generated values if column not found\n",
    "    if attr.value_type == AttributeType.INTEGER:\n",
    "        if selectivity == \"low\":\n",
    "            return str(random.randint(80, 100)), 0.1\n",
    "        elif selectivity == \"high\":\n",
    "            return str(random.randint(0, 20)), 0.5\n",
    "        else:\n",
    "            return str(random.randint(30, 70)), 0.25\n",
    "    \n",
    "    elif attr.value_type == AttributeType.FLOAT:\n",
    "        if selectivity == \"low\":\n",
    "            return f\"{random.uniform(80, 100):.2f}\", 0.1\n",
    "        elif selectivity == \"high\":\n",
    "            return f\"{random.uniform(0, 20):.2f}\", 0.5\n",
    "        else:\n",
    "            return f\"{random.uniform(30, 70):.2f}\", 0.25\n",
    "    \n",
    "    elif attr.value_type == AttributeType.STRING:\n",
    "        if attr.usage == AttributeUsage.CATEGORICAL:\n",
    "            samples = [\"'value_A'\", \"'value_B'\", \"'value_C'\"]\n",
    "        else:\n",
    "            samples = [\"'%keyword%'\", \"'prefix%'\", \"'%suffix'\", \"'exact_match'\"]\n",
    "        return random.choice(samples), 0.1\n",
    "    \n",
    "    elif attr.value_type == AttributeType.BOOLEAN:\n",
    "        return random.choice([\"0\", \"1\"]), 0.5\n",
    "    \n",
    "    return \"'unknown'\", 0.0\n",
    "\n",
    "\n",
    "def generate_predicate(attr: Attribute, selectivity: str = \"medium\", \n",
    "                       stats: DataStatistics = None) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Generate a single filter predicate: {Attribute}{Operator}{Literal}\n",
    "    \n",
    "    Args:\n",
    "        attr: The attribute for the predicate\n",
    "        selectivity: Selectivity level for the literal\n",
    "        stats: DataStatistics object for real data\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (predicate_string, selectivity_ratio)\n",
    "    \"\"\"\n",
    "    if stats is None:\n",
    "        stats = data_stats\n",
    "    \n",
    "    # Choose operator based on attribute type\n",
    "    if attr.value_type in [AttributeType.INTEGER, AttributeType.FLOAT]:\n",
    "        operator = random.choice(NUMERIC_OPERATORS)\n",
    "    elif attr.usage == AttributeUsage.CATEGORICAL:\n",
    "        operator = random.choice(CATEGORICAL_OPERATORS)\n",
    "    else:\n",
    "        operator = random.choice(STRING_OPERATORS)\n",
    "    \n",
    "    literal, ratio = generate_literal(attr, selectivity, stats)\n",
    "    \n",
    "    # Handle special operators\n",
    "    # if operator == 'LIKE':\n",
    "    #     # For LIKE, use pattern matching\n",
    "    #     col_info = stats.get_column_info(attr.name)\n",
    "    #     if col_info and col_info['type'] == 'categorical':\n",
    "    #         # Use actual value with wildcards\n",
    "    #         base_value = literal.strip(\"'\")\n",
    "    #         like_literal = f\"'%{base_value[:3]}%'\" if len(base_value) > 3 else f\"'%{base_value}%'\"\n",
    "    #         return f\"{attr.name} LIKE {like_literal}\", ratio * 2  # LIKE usually matches more\n",
    "    #     return f\"{attr.name} LIKE {literal}\", ratio\n",
    "    \n",
    "    # elif operator == 'IN':\n",
    "    #     # Generate multiple values for IN clause\n",
    "    #     literals_with_ratios = [generate_literal(attr, selectivity, stats) for _ in range(random.randint(2, 4))]\n",
    "    #     literals = [l[0] for l in literals_with_ratios]\n",
    "    #     combined_ratio = min(1.0, sum(l[1] for l in literals_with_ratios))\n",
    "    #     return f\"{attr.name} IN ({', '.join(literals)})\", combined_ratio\n",
    "    \n",
    "    # else:\n",
    "    #     return f\"{attr.name} {operator} {literal}\", ratio\n",
    "    return f\"{attr.name} {operator} {literal}\", ratio\n",
    "\n",
    "\n",
    "def generate_filter_query(\n",
    "    attributes: List[Attribute],\n",
    "    table: str,\n",
    "    subcategory: int,\n",
    "    select_attr_num: int = 2,\n",
    "    image_num: int = 1,\n",
    "    filter_count: int = 3,\n",
    "    seed: int = None\n",
    ") -> Tuple[str, Dict]:\n",
    "    \"\"\"\n",
    "    Generate a Filter query based on the subcategory.\n",
    "    \n",
    "    Subcategories:\n",
    "        1: Single filter - WHERE {A}{O}{L}\n",
    "        2: Two filters with AND - WHERE {A}{O}{L} AND {A}{O}{L}\n",
    "        3: Two filters with OR - WHERE {A}{O}{L} OR {A}{O}{L}\n",
    "        4: Multiple filters with AND - WHERE {A}{O}{L} (AND {A}{O}{L})^n\n",
    "        5: Multiple filters with OR - WHERE {A}{O}{L} (OR {A}{O}{L})^n\n",
    "        6: Mixed AND/OR combination - WHERE (... AND ...) OR (... AND ...)\n",
    "    \n",
    "    Args:\n",
    "        attributes: List of available Attribute objects\n",
    "        table: Table name\n",
    "        subcategory: Filter subcategory (1-6)\n",
    "        select_attr_num: Number of attributes in SELECT clause\n",
    "        image_num: Number of image attributes to include\n",
    "        filter_count: Number of filters for subcategory 4, 5, 6 (default 3)\n",
    "        seed: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (SQL query string, metadata dict)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    # Generate SELECT clause using existing function\n",
    "    select_query, selected_attrs = generate_select_query(\n",
    "        attributes, table, select_attr_num, image_num, seed\n",
    "    )\n",
    "    select_clause = select_query.replace(f\" FROM {table};\", \"\")\n",
    "    \n",
    "    # Get filterable attributes (exclude image attributes for filtering)\n",
    "    filterable_attrs = [a for a in attributes if a.modality != AttributeModality.IMAGE]\n",
    "    \n",
    "    if not filterable_attrs:\n",
    "        raise ValueError(\"No filterable attributes available\")\n",
    "    \n",
    "    # Generate predicates based on subcategory\n",
    "    metadata = {\n",
    "        \"subcategory\": subcategory,\n",
    "        \"filter_combination\": \"\",\n",
    "        \"num_filters\": 0,\n",
    "        \"predicates\": []\n",
    "    }\n",
    "    \n",
    "    if subcategory == 1:\n",
    "        # Single filter\n",
    "        attr = random.choice(filterable_attrs)\n",
    "        selectivity = random.choice([\"low\", \"medium\", \"high\"])\n",
    "        predicate, ratio = generate_predicate(attr, selectivity)\n",
    "        where_clause = predicate\n",
    "        metadata[\"filter_combination\"] = \"single\"\n",
    "        metadata[\"num_filters\"] = 1\n",
    "        metadata[\"predicates\"] = [predicate]\n",
    "        metadata[\"selectivity_ratios\"] = [ratio]\n",
    "    \n",
    "    elif subcategory == 2:\n",
    "        # Two filters with AND\n",
    "        attrs = random.sample(filterable_attrs, min(2, len(filterable_attrs)))\n",
    "        pred_results = [generate_predicate(a, random.choice([\"low\", \"medium\", \"high\"])) for a in attrs]\n",
    "        predicates = [p[0] for p in pred_results]\n",
    "        ratios = [p[1] for p in pred_results]\n",
    "        where_clause = \" AND \".join(predicates)\n",
    "        metadata[\"filter_combination\"] = \"AND\"\n",
    "        metadata[\"num_filters\"] = 2\n",
    "        metadata[\"predicates\"] = predicates\n",
    "        metadata[\"selectivity_ratios\"] = ratios\n",
    "    \n",
    "    elif subcategory == 3:\n",
    "        # Two filters with OR\n",
    "        attrs = random.sample(filterable_attrs, min(2, len(filterable_attrs)))\n",
    "        pred_results = [generate_predicate(a, random.choice([\"low\", \"medium\", \"high\"])) for a in attrs]\n",
    "        predicates = [p[0] for p in pred_results]\n",
    "        ratios = [p[1] for p in pred_results]\n",
    "        where_clause = \" OR \".join(predicates)\n",
    "        metadata[\"filter_combination\"] = \"OR\"\n",
    "        metadata[\"num_filters\"] = 2\n",
    "        metadata[\"predicates\"] = predicates\n",
    "        metadata[\"selectivity_ratios\"] = ratios\n",
    "    \n",
    "    elif subcategory == 4:\n",
    "        # Multiple filters with AND (3 or more)\n",
    "        n = max(3, filter_count)\n",
    "        attrs = random.choices(filterable_attrs, k=n)\n",
    "        pred_results = [generate_predicate(a, random.choice([\"low\", \"medium\", \"high\"])) for a in attrs]\n",
    "        predicates = [p[0] for p in pred_results]\n",
    "        ratios = [p[1] for p in pred_results]\n",
    "        where_clause = \" AND \".join(predicates)\n",
    "        metadata[\"filter_combination\"] = \"AND\"\n",
    "        metadata[\"num_filters\"] = n\n",
    "        metadata[\"predicates\"] = predicates\n",
    "        metadata[\"selectivity_ratios\"] = ratios\n",
    "    \n",
    "    elif subcategory == 5:\n",
    "        # Multiple filters with OR (3 or more)\n",
    "        n = max(3, filter_count)\n",
    "        attrs = random.choices(filterable_attrs, k=n)\n",
    "        pred_results = [generate_predicate(a, random.choice([\"low\", \"medium\", \"high\"])) for a in attrs]\n",
    "        predicates = [p[0] for p in pred_results]\n",
    "        ratios = [p[1] for p in pred_results]\n",
    "        where_clause = \" OR \".join(predicates)\n",
    "        metadata[\"filter_combination\"] = \"OR\"\n",
    "        metadata[\"num_filters\"] = n\n",
    "        metadata[\"predicates\"] = predicates\n",
    "        metadata[\"selectivity_ratios\"] = ratios\n",
    "    \n",
    "    elif subcategory == 6:\n",
    "        # Mixed AND/OR combination: (p1 AND p2) OR (p3 AND p4) or similar CNF/DNF\n",
    "        n = max(4, filter_count)\n",
    "        attrs = random.choices(filterable_attrs, k=n)\n",
    "        pred_results = [generate_predicate(a, random.choice([\"low\", \"medium\", \"high\"])) for a in attrs]\n",
    "        predicates = [p[0] for p in pred_results]\n",
    "        ratios = [p[1] for p in pred_results]\n",
    "        \n",
    "        # Create groups for mixed combination\n",
    "        mid = n // 2\n",
    "        group1 = \" AND \".join(predicates[:mid])\n",
    "        group2 = \" AND \".join(predicates[mid:])\n",
    "        where_clause = f\"({group1}) OR ({group2})\"\n",
    "        metadata[\"filter_combination\"] = \"AND_OR_mixed\"\n",
    "        metadata[\"num_filters\"] = n\n",
    "        metadata[\"predicates\"] = predicates\n",
    "        metadata[\"selectivity_ratios\"] = ratios\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid subcategory: {subcategory}. Must be 1-6.\")\n",
    "    \n",
    "    # Build final SQL query\n",
    "    sql_query = f\"{select_clause} FROM {table} WHERE {where_clause};\"\n",
    "    \n",
    "    metadata[\"selected_attributes\"] = [a.name for a in selected_attrs]\n",
    "    metadata[\"where_clause\"] = where_clause\n",
    "    \n",
    "    return sql_query, metadata\n",
    "\n",
    "\n",
    "# Example: Generate one query for each subcategory with REAL data values\n",
    "print(\"=\" * 70)\n",
    "print(\"FILTER QUERY EXAMPLES (6 Subcategories) - Using Real Data\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "subcategory_names = {\n",
    "    1: \"Single Filter\",\n",
    "    2: \"Two Filters (AND)\",\n",
    "    3: \"Two Filters (OR)\",\n",
    "    4: \"Multiple Filters (AND)\",\n",
    "    5: \"Multiple Filters (OR)\",\n",
    "    6: \"Mixed AND/OR Combination\"\n",
    "}\n",
    "\n",
    "for subcat in range(1, 7):\n",
    "    print(f\"\\n{'â”€' * 70}\")\n",
    "    print(f\"Subcategory {subcat}: {subcategory_names[subcat]}\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    \n",
    "    query, meta = generate_filter_query(\n",
    "        attributes, \n",
    "        table=\"Art\", \n",
    "        subcategory=subcat,\n",
    "        select_attr_num=3,\n",
    "        image_num=1,\n",
    "        filter_count=4\n",
    "    )\n",
    "    \n",
    "    print(f\"SQL: {query}\")\n",
    "    print(f\"  Combination: {meta['filter_combination']}\")\n",
    "    print(f\"  Num Filters: {meta['num_filters']}\")\n",
    "    print(f\"  Predicates:\")\n",
    "    for pred, ratio in zip(meta['predicates'], meta['selectivity_ratios']):\n",
    "        print(f\"    â€¢ {pred}  (selectivity: {ratio:.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb089a",
   "metadata": {},
   "source": [
    "## Aggregate Category\n",
    "\n",
    "\n",
    "\\noindent\\underline{(3) \\textit{For the \\texttt{Agg} category}}, during query generation, we randomly sample the group-by attribute, the aggregated attributes, and the aggregation functions (such as \\texttt{Count}) to populate the corresponding placeholders (i.e., \\{agg\\_func\\}(\\{Attribute\\}(s)). \n",
    "\n",
    "Template\n",
    "SELECT {attribute(s)}, {Aggregation func}({numerical attribute}) FROM {table} GROUP BY {categorical attribute}.\n",
    "å…¶ä¸­, COUNT({any attribute})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f05bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "AGGREGATION QUERY EXAMPLES\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Example 1: Single GROUP BY + COUNT\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "SQL: SELECT nationality, nba_championships, fiba_world_cup, MIN(fiba_world_cup) AS min_fiba_world_cup FROM Art GROUP BY nationality;\n",
      "  GROUP BY: ['nationality']\n",
      "  Aggregations: [{'function': 'MIN', 'attribute': 'fiba_world_cup', 'alias': 'min_fiba_world_cup'}]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Example 2: Multiple GROUP BY + Multiple Aggregations\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "SQL: SELECT position, nationality, NBA_team, age, COUNT(mvp_awards) AS count_mvp_awards, MAX(championships) AS max_championships FROM Art GROUP BY position, nationality;\n",
      "  GROUP BY: ['position', 'nationality']\n",
      "  Aggregations: [{'function': 'COUNT', 'attribute': 'mvp_awards', 'alias': 'count_mvp_awards'}, {'function': 'MAX', 'attribute': 'championships', 'alias': 'max_championships'}]\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Example 3: Various Aggregation Functions\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. SELECT position, population, MIN(age) AS min_age FROM Player GROUP BY position;\n",
      "     â†’ MIN(age)\n",
      "  2. SELECT nationality, birth_date, MIN(olympic_gold_medals) AS min_olympic_gold_medals FROM Player GROUP BY nationality;\n",
      "     â†’ MIN(olympic_gold_medals)\n",
      "  3. SELECT nationality, championships, SUM(mvp_awards) AS sum_mvp_awards FROM Player GROUP BY nationality;\n",
      "     â†’ SUM(mvp_awards)\n"
     ]
    }
   ],
   "source": [
    "# Aggregation functions\n",
    "AGG_FUNCTIONS = ['COUNT', 'SUM', 'AVG', 'MIN', 'MAX']\n",
    "# COUNT can be applied to any attribute, others require numerical attributes\n",
    "NUMERIC_ONLY_AGG = ['SUM', 'AVG', 'MIN', 'MAX']\n",
    "\n",
    "\n",
    "def generate_agg_query(\n",
    "    attributes: List[Attribute],\n",
    "    table: str,\n",
    "    select_attr_num: int = 2,\n",
    "    image_num: int = 1,\n",
    "    num_group_by: int = 1,\n",
    "    num_agg_funcs: int = 1,\n",
    "    seed: int = None\n",
    ") -> Tuple[str, Dict]:\n",
    "    \"\"\"\n",
    "    Generate an Aggregation query.\n",
    "    \n",
    "    Template: SELECT {attribute(s)}, {agg_func}({attribute}) FROM {table} GROUP BY {categorical attribute(s)}\n",
    "    \n",
    "    Rules:\n",
    "    - GROUP BY attributes must be categorical (usage == CATEGORICAL)\n",
    "    - COUNT can be applied to any attribute\n",
    "    - SUM, AVG, MIN, MAX can only be applied to numerical attributes\n",
    "    - At least one image attribute should be in SELECT (if available)\n",
    "    \n",
    "    Args:\n",
    "        attributes: List of available Attribute objects\n",
    "        table: Table name\n",
    "        select_attr_num: Number of regular attributes in SELECT clause (excluding aggregations)\n",
    "        image_num: Number of image attributes to include\n",
    "        num_group_by: Number of GROUP BY attributes\n",
    "        num_agg_funcs: Number of aggregation functions to apply\n",
    "        seed: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (SQL query string, metadata dict)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    # Separate attributes by their properties\n",
    "    categorical_attrs = [a for a in attributes if a.usage == AttributeUsage.CATEGORICAL]\n",
    "    numerical_attrs = [a for a in attributes if a.usage == AttributeUsage.NUMERICAL]\n",
    "    image_attrs = [a for a in attributes if a.modality == AttributeModality.IMAGE]\n",
    "    non_image_attrs = [a for a in attributes if a.modality != AttributeModality.IMAGE]\n",
    "    \n",
    "    if not categorical_attrs:\n",
    "        raise ValueError(\"No categorical attributes available for GROUP BY\")\n",
    "    \n",
    "    # Select GROUP BY attributes (must be categorical)\n",
    "    num_group_by = min(num_group_by, len(categorical_attrs))\n",
    "    group_by_attrs = random.sample(categorical_attrs, num_group_by)\n",
    "    \n",
    "    # Select regular attributes for SELECT clause (including at least one image if available)\n",
    "    selected_attrs = []\n",
    "    \n",
    "    # Add image attributes if available\n",
    "    if image_attrs and image_num > 0:\n",
    "        num_image = min(image_num, len(image_attrs))\n",
    "        selected_attrs.extend(random.sample(image_attrs, num_image))\n",
    "    \n",
    "    # Add non-image attributes (exclude those already in group_by)\n",
    "    remaining_non_image = [a for a in non_image_attrs if a not in group_by_attrs and a not in selected_attrs]\n",
    "    remaining_slots = select_attr_num - len(selected_attrs)\n",
    "    \n",
    "    if remaining_non_image and remaining_slots > 0:\n",
    "        num_to_add = min(remaining_slots, len(remaining_non_image))\n",
    "        selected_attrs.extend(random.sample(remaining_non_image, num_to_add))\n",
    "    \n",
    "    # Generate aggregation expressions\n",
    "    agg_expressions = []\n",
    "    agg_metadata = []\n",
    "    \n",
    "    for _ in range(num_agg_funcs):\n",
    "        # Randomly choose aggregation function\n",
    "        agg_func = random.choice(AGG_FUNCTIONS)\n",
    "        \n",
    "        if agg_func in NUMERIC_ONLY_AGG:\n",
    "            # Must use numerical attribute\n",
    "            if not numerical_attrs:\n",
    "                agg_func = 'COUNT'  # Fallback to COUNT\n",
    "                agg_attr = random.choice(non_image_attrs)\n",
    "            else:\n",
    "                agg_attr = random.choice(numerical_attrs)\n",
    "        else:\n",
    "            # COUNT can use any attribute (prefer non-image)\n",
    "            agg_attr = random.choice(non_image_attrs) if non_image_attrs else random.choice(attributes)\n",
    "        \n",
    "        # Create aggregation expression with alias\n",
    "        alias = f\"{agg_func.lower()}_{agg_attr.name}\"\n",
    "        agg_expr = f\"{agg_func}({agg_attr.name}) AS {alias}\"\n",
    "        agg_expressions.append(agg_expr)\n",
    "        \n",
    "        agg_metadata.append({\n",
    "            \"function\": agg_func,\n",
    "            \"attribute\": agg_attr.name,\n",
    "            \"alias\": alias\n",
    "        })\n",
    "    \n",
    "    # Build SELECT clause\n",
    "    # Include: group_by attributes + selected attributes + aggregation expressions\n",
    "    select_parts = []\n",
    "    \n",
    "    # Add group by attributes first\n",
    "    for attr in group_by_attrs:\n",
    "        select_parts.append(attr.name)\n",
    "    \n",
    "    # Add selected attributes (image and others)\n",
    "    for attr in selected_attrs:\n",
    "        if attr.name not in select_parts:\n",
    "            select_parts.append(attr.name)\n",
    "    \n",
    "    # Add aggregation expressions\n",
    "    select_parts.extend(agg_expressions)\n",
    "    \n",
    "    select_clause = \", \".join(select_parts)\n",
    "    \n",
    "    # Build GROUP BY clause\n",
    "    group_by_clause = \", \".join([attr.name for attr in group_by_attrs])\n",
    "    \n",
    "    # Build final SQL query\n",
    "    sql_query = f\"SELECT {select_clause} FROM {table} GROUP BY {group_by_clause};\"\n",
    "    \n",
    "    metadata = {\n",
    "        \"category\": \"Agg\",\n",
    "        \"group_by_attributes\": [attr.name for attr in group_by_attrs],\n",
    "        \"selected_attributes\": [attr.name for attr in selected_attrs],\n",
    "        \"aggregations\": agg_metadata,\n",
    "        \"num_group_by\": num_group_by,\n",
    "        \"num_aggregations\": num_agg_funcs\n",
    "    }\n",
    "    \n",
    "    return sql_query, metadata\n",
    "\n",
    "\n",
    "# Example: Generate aggregation queries\n",
    "print(\"=\" * 70)\n",
    "print(\"AGGREGATION QUERY EXAMPLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example 1: Single GROUP BY, single aggregation\n",
    "print(f\"\\n{'â”€' * 70}\")\n",
    "print(\"Example 1: Single GROUP BY + COUNT\")\n",
    "print(f\"{'â”€' * 70}\")\n",
    "query, meta = generate_agg_query(\n",
    "    attributes, \n",
    "    table=\"Art\", \n",
    "    select_attr_num=2,\n",
    "    image_num=1,\n",
    "    num_group_by=1,\n",
    "    num_agg_funcs=1\n",
    ")\n",
    "print(f\"SQL: {query}\")\n",
    "print(f\"  GROUP BY: {meta['group_by_attributes']}\")\n",
    "print(f\"  Aggregations: {meta['aggregations']}\")\n",
    "\n",
    "# Example 2: Multiple GROUP BY, multiple aggregations\n",
    "print(f\"\\n{'â”€' * 70}\")\n",
    "print(\"Example 2: Multiple GROUP BY + Multiple Aggregations\")\n",
    "print(f\"{'â”€' * 70}\")\n",
    "query, meta = generate_agg_query(\n",
    "    attributes, \n",
    "    table=\"Art\", \n",
    "    select_attr_num=2,\n",
    "    image_num=1,\n",
    "    num_group_by=2,\n",
    "    num_agg_funcs=2\n",
    ")\n",
    "print(f\"SQL: {query}\")\n",
    "print(f\"  GROUP BY: {meta['group_by_attributes']}\")\n",
    "print(f\"  Aggregations: {meta['aggregations']}\")\n",
    "\n",
    "# Example 3: With different aggregation functions\n",
    "print(f\"\\n{'â”€' * 70}\")\n",
    "print(\"Example 3: Various Aggregation Functions\")\n",
    "print(f\"{'â”€' * 70}\")\n",
    "for i in range(3):\n",
    "    query, meta = generate_agg_query(\n",
    "        attributes, \n",
    "        table=\"Player\", \n",
    "        select_attr_num=1,\n",
    "        image_num=1,\n",
    "        num_group_by=1,\n",
    "        num_agg_funcs=1,\n",
    "        seed=i*10\n",
    "    )\n",
    "    print(f\"  {i+1}. {query}\")\n",
    "    print(f\"     â†’ {meta['aggregations'][0]['function']}({meta['aggregations'][0]['attribute']})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8eda9",
   "metadata": {},
   "source": [
    "## JOIN Category\n",
    "\n",
    "\\noindent\\underline{(4) \\textit{For the \\texttt{Join} category}}, \n",
    "to thoroughly evaluate the capacities of different systems in optimizing join queries, we curate two sub-categories of join queries, i.e., binary joins and multi-table joins, where more tables incur higher computation cost. During query generation, we explicitly define a join graph w.r.t. each dataset. For example, in \\med, valid join paths include Disease $\\bowtie$ Drug, along with their corresponding join keys (e.g., Disease.name = Drug.disease). Similarly, in \\nba, we have Players $\\bowtie$ Teams $\\bowtie$ Managers, together with  join keys that link these tables.\n",
    "\n",
    "two table joins template:\n",
    "SELECT {attribute(s)} FROM {table1} JOIN {table2} on {table1.join_key} = {table2.join_key}\n",
    "\n",
    "etc.\n",
    "\n",
    "è¾“å…¥ï¼Œæ‰€æœ‰ä¼šç”¨åˆ°çš„è¡¨çš„gtçš„åœ°å€ e.g. {player:\"xxx\", team:\"xxx\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "463e6352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Player Join Graph initialized\n",
      "   Tables: ['player', 'team', 'manager', 'city']\n",
      "   Join Paths:\n",
      "      player.team = team.team_name\n",
      "      team.location = city.city_name\n",
      "      team.ownership = manager.name\n",
      "      manager.nba_team = team.team_name\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class JoinPath:\n",
    "    \"\"\"Represents a join relationship between two tables.\"\"\"\n",
    "    left_table: str\n",
    "    right_table: str\n",
    "    left_key: str\n",
    "    right_key: str\n",
    "    \n",
    "    def to_sql_condition(self) -> str:\n",
    "        \"\"\"Return the SQL JOIN condition.\"\"\"\n",
    "        return f\"{self.left_table}.{self.left_key} = {self.right_table}.{self.right_key}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TableConfig:\n",
    "    \"\"\"Configuration for a single table.\"\"\"\n",
    "    name: str\n",
    "    csv_path: str\n",
    "    attributes: List[Attribute]\n",
    "\n",
    "\n",
    "class JoinGraph:\n",
    "    \"\"\"\n",
    "    Manages join relationships between tables and generates JOIN queries.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tables: Dict[str, TableConfig], join_paths: List[JoinPath]):\n",
    "        \"\"\"\n",
    "        Initialize the join graph.\n",
    "        \n",
    "        Args:\n",
    "            tables: Dictionary mapping table names to TableConfig objects\n",
    "            join_paths: List of JoinPath objects defining valid joins\n",
    "        \"\"\"\n",
    "        self.tables = tables\n",
    "        self.join_paths = join_paths\n",
    "        self.data_stats = {}  # DataStatistics for each table\n",
    "        \n",
    "        # Load data statistics for each table\n",
    "        for table_name, config in tables.items():\n",
    "            if os.path.exists(config.csv_path):\n",
    "                self.data_stats[table_name] = DataStatistics(config.csv_path)\n",
    "    \n",
    "    def get_join_path(self, table1: str, table2: str) -> Optional[JoinPath]:\n",
    "        \"\"\"Find a join path between two tables.\"\"\"\n",
    "        for jp in self.join_paths:\n",
    "            if (jp.left_table == table1 and jp.right_table == table2):\n",
    "                return jp\n",
    "            if (jp.left_table == table2 and jp.right_table == table1):\n",
    "                # Return reversed join path\n",
    "                return JoinPath(table1, table2, jp.right_key, jp.left_key)\n",
    "        return None\n",
    "    \n",
    "    def find_multi_table_path(self, tables: List[str]) -> List[JoinPath]:\n",
    "        \"\"\"\n",
    "        Find a sequence of join paths connecting multiple tables.\n",
    "        Uses simple BFS to find connected path.\n",
    "        \"\"\"\n",
    "        if len(tables) < 2:\n",
    "            return []\n",
    "        \n",
    "        path = []\n",
    "        remaining = set(tables[1:])\n",
    "        current = tables[0]\n",
    "        visited = {current}\n",
    "        \n",
    "        while remaining:\n",
    "            found = False\n",
    "            for next_table in list(remaining):\n",
    "                jp = self.get_join_path(current, next_table)\n",
    "                if jp:\n",
    "                    path.append(jp)\n",
    "                    visited.add(next_table)\n",
    "                    remaining.remove(next_table)\n",
    "                    current = next_table\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if not found:\n",
    "                # Try to find path through visited tables\n",
    "                for v in visited:\n",
    "                    for next_table in list(remaining):\n",
    "                        jp = self.get_join_path(v, next_table)\n",
    "                        if jp:\n",
    "                            path.append(jp)\n",
    "                            visited.add(next_table)\n",
    "                            remaining.remove(next_table)\n",
    "                            found = True\n",
    "                            break\n",
    "                    if found:\n",
    "                        break\n",
    "            \n",
    "            if not found:\n",
    "                raise ValueError(f\"Cannot find join path for tables: {remaining}\")\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    def get_all_attributes(self, table_names: List[str] = None) -> List[Attribute]:\n",
    "        \"\"\"Get all attributes from specified tables (or all tables if None).\"\"\"\n",
    "        if table_names is None:\n",
    "            table_names = list(self.tables.keys())\n",
    "        \n",
    "        all_attrs = []\n",
    "        for name in table_names:\n",
    "            if name in self.tables:\n",
    "                all_attrs.extend(self.tables[name].attributes)\n",
    "        return all_attrs\n",
    "\n",
    "\n",
    "def generate_binary_join_query(\n",
    "    join_graph: JoinGraph,\n",
    "    table1: str,\n",
    "    table2: str,\n",
    "    select_attr_num: int = 3,\n",
    "    seed: int = None\n",
    ") -> Tuple[str, Dict]:\n",
    "    \"\"\"\n",
    "    Generate a binary (2-table) JOIN query.\n",
    "    \n",
    "    Template: SELECT {attributes} FROM {table1} JOIN {table2} ON {join_condition}\n",
    "    \n",
    "    Args:\n",
    "        join_graph: JoinGraph with table configurations\n",
    "        table1: First table name\n",
    "        table2: Second table name\n",
    "        select_attr_num: Number of attributes to select\n",
    "        seed: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (SQL query string, metadata dict)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    # Get join path\n",
    "    join_path = join_graph.get_join_path(table1, table2)\n",
    "    if not join_path:\n",
    "        raise ValueError(f\"No join path between {table1} and {table2}\")\n",
    "    \n",
    "    # Get attributes from both tables\n",
    "    attrs1 = join_graph.tables[table1].attributes\n",
    "    attrs2 = join_graph.tables[table2].attributes\n",
    "    all_attrs = attrs1 + attrs2\n",
    "    \n",
    "    # Select random attributes (ensure from both tables)\n",
    "    selected = []\n",
    "    num_from_t1 = max(1, select_attr_num // 2)\n",
    "    num_from_t2 = select_attr_num - num_from_t1\n",
    "    \n",
    "    if attrs1:\n",
    "        selected.extend(random.sample(attrs1, min(num_from_t1, len(attrs1))))\n",
    "    if attrs2:\n",
    "        selected.extend(random.sample(attrs2, min(num_from_t2, len(attrs2))))\n",
    "    \n",
    "    random.shuffle(selected)\n",
    "    \n",
    "    # Build SELECT clause with table prefixes\n",
    "    select_parts = [f\"{attr.table}.{attr.name}\" for attr in selected]\n",
    "    select_clause = \", \".join(select_parts)\n",
    "    \n",
    "    # Build SQL query\n",
    "    sql_query = f\"SELECT {select_clause} FROM {table1} JOIN {table2} ON {join_path.to_sql_condition()};\"\n",
    "    \n",
    "    metadata = {\n",
    "        \"category\": \"Join\",\n",
    "        \"subcategory\": \"binary_join\",\n",
    "        \"tables\": [table1, table2],\n",
    "        \"join_condition\": join_path.to_sql_condition(),\n",
    "        \"selected_attributes\": [f\"{a.table}.{a.name}\" for a in selected]\n",
    "    }\n",
    "    \n",
    "    return sql_query, metadata\n",
    "\n",
    "\n",
    "def generate_multi_table_join_query(\n",
    "    join_graph: JoinGraph,\n",
    "    tables: List[str],\n",
    "    select_attr_num: int = 4,\n",
    "    seed: int = None\n",
    ") -> Tuple[str, Dict]:\n",
    "    \"\"\"\n",
    "    Generate a multi-table (>2) JOIN query.\n",
    "    \n",
    "    Template: SELECT {attributes} FROM {table1} \n",
    "              JOIN {table2} ON {cond1} \n",
    "              JOIN {table3} ON {cond2} ...\n",
    "    \n",
    "    Args:\n",
    "        join_graph: JoinGraph with table configurations\n",
    "        tables: List of table names to join (minimum 3)\n",
    "        select_attr_num: Number of attributes to select\n",
    "        seed: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (SQL query string, metadata dict)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    if len(tables) < 3:\n",
    "        raise ValueError(\"Multi-table join requires at least 3 tables\")\n",
    "    \n",
    "    # Find join path\n",
    "    join_paths = join_graph.find_multi_table_path(tables)\n",
    "    \n",
    "    # Get attributes from all tables\n",
    "    all_attrs = []\n",
    "    for table in tables:\n",
    "        all_attrs.extend(join_graph.tables[table].attributes)\n",
    "    \n",
    "    # Select attributes (at least one from each table)\n",
    "    selected = []\n",
    "    per_table = max(1, select_attr_num // len(tables))\n",
    "    \n",
    "    for table in tables:\n",
    "        table_attrs = join_graph.tables[table].attributes\n",
    "        if table_attrs:\n",
    "            num_select = min(per_table, len(table_attrs))\n",
    "            selected.extend(random.sample(table_attrs, num_select))\n",
    "    \n",
    "    # Add more if needed\n",
    "    remaining = [a for a in all_attrs if a not in selected]\n",
    "    while len(selected) < select_attr_num and remaining:\n",
    "        selected.append(random.choice(remaining))\n",
    "        remaining.remove(selected[-1])\n",
    "    \n",
    "    random.shuffle(selected)\n",
    "    \n",
    "    # Build SELECT clause\n",
    "    select_parts = [f\"{attr.table}.{attr.name}\" for attr in selected]\n",
    "    select_clause = \", \".join(select_parts)\n",
    "    \n",
    "    # Build FROM and JOIN clauses\n",
    "    from_table = tables[0]\n",
    "    join_clauses = []\n",
    "    \n",
    "    joined_tables = {from_table}\n",
    "    for jp in join_paths:\n",
    "        # Determine which table to add\n",
    "        if jp.right_table not in joined_tables:\n",
    "            join_clauses.append(f\"JOIN {jp.right_table} ON {jp.to_sql_condition()}\")\n",
    "            joined_tables.add(jp.right_table)\n",
    "        elif jp.left_table not in joined_tables:\n",
    "            # Reverse the join\n",
    "            reversed_cond = f\"{jp.right_table}.{jp.right_key} = {jp.left_table}.{jp.left_key}\"\n",
    "            join_clauses.append(f\"JOIN {jp.left_table} ON {reversed_cond}\")\n",
    "            joined_tables.add(jp.left_table)\n",
    "    \n",
    "    # Build SQL query\n",
    "    sql_query = f\"SELECT {select_clause} FROM {from_table} \" + \" \".join(join_clauses) + \";\"\n",
    "    \n",
    "    metadata = {\n",
    "        \"category\": \"Join\",\n",
    "        \"subcategory\": \"multi_table_join\",\n",
    "        \"tables\": tables,\n",
    "        \"num_joins\": len(join_paths),\n",
    "        \"join_conditions\": [jp.to_sql_condition() for jp in join_paths],\n",
    "        \"selected_attributes\": [f\"{a.table}.{a.name}\" for a in selected]\n",
    "    }\n",
    "    \n",
    "    return sql_query, metadata\n",
    "\n",
    "\n",
    "def save_queries_to_file(queries: List[Dict], output_path: str, format: str = \"json\"):\n",
    "    \"\"\"\n",
    "    Save generated queries to a file.\n",
    "    \n",
    "    Args:\n",
    "        queries: List of query dictionaries with 'sql' and 'metadata' keys\n",
    "        output_path: Path to save the file\n",
    "        format: Output format ('json' or 'sql')\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    if format == \"json\":\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(queries, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"âœ… Saved {len(queries)} queries to {output_path}\")\n",
    "        \n",
    "    elif format == \"sql\":\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            for i, q in enumerate(queries):\n",
    "                subcategory = q.get('metadata', {}).get('subcategory', 'unknown')\n",
    "                tables = q.get('metadata', {}).get('tables', [])\n",
    "                f.write(f\"-- Query {i+1}: {subcategory} ({', '.join(tables) if tables else 'N/A'})\\n\")\n",
    "                f.write(q['sql'] + \"\\n\\n\")\n",
    "        print(f\"âœ… Saved {len(queries)} queries to {output_path}\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported format: {format}. Use 'json' or 'sql'.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Setup Player Dataset Join Graph\n",
    "# =============================================================================\n",
    "\n",
    "# Define Player dataset tables and their CSV paths\n",
    "player_base_path = \"/data/dengqiyan/UDA-Bench/Query/Player\"\n",
    "\n",
    "# Load attributes for each table\n",
    "player_attrs_data = json.load(open(f\"{player_base_path}/Player_attributes.json\"))\n",
    "\n",
    "def attrs_from_json(attr_list: List[Dict]) -> List[Attribute]:\n",
    "    \"\"\"Convert JSON attribute list to Attribute objects.\"\"\"\n",
    "    type_map = {\"str\": AttributeType.STRING, \"int\": AttributeType.INTEGER, \"float\": AttributeType.FLOAT}\n",
    "    usage_map = {\"categorical\": AttributeUsage.CATEGORICAL, \"numerical\": AttributeUsage.NUMERICAL, \"general\": AttributeUsage.GENERAL}\n",
    "    modality_map = {\"text\": AttributeModality.TEXT, \"image\": AttributeModality.IMAGE}\n",
    "    \n",
    "    return [\n",
    "        Attribute(\n",
    "            name=a[\"name\"], table=a[\"table\"],\n",
    "            value_type=type_map.get(a[\"value_type\"], AttributeType.STRING),\n",
    "            usage=usage_map.get(a[\"usage\"], AttributeUsage.GENERAL),\n",
    "            modality=modality_map.get(a[\"modality\"], AttributeModality.TEXT),\n",
    "            is_nullable=a.get(\"is_nullable\", False),\n",
    "            description=a.get(\"description\", \"\")\n",
    "        ) for a in attr_list\n",
    "    ]\n",
    "\n",
    "# Create table configurations\n",
    "player_tables = {\n",
    "    \"player\": TableConfig(\"player\", f\"{player_base_path}/player.csv\", attrs_from_json(player_attrs_data[\"player\"])),\n",
    "    \"team\": TableConfig(\"team\", f\"{player_base_path}/team.csv\", attrs_from_json(player_attrs_data[\"team\"])),\n",
    "    \"manager\": TableConfig(\"manager\", f\"{player_base_path}/manager.csv\", attrs_from_json(player_attrs_data[\"manager\"])),\n",
    "    \"city\": TableConfig(\"city\", f\"{player_base_path}/city.csv\", attrs_from_json(player_attrs_data[\"city\"])),\n",
    "}\n",
    "\n",
    "# Define join paths based on the data structure\n",
    "# player.team = team.team_name\n",
    "# team.location = city.city_name\n",
    "# team.ownership = manager.name\n",
    "# manager.nba_team = team.team_name\n",
    "player_join_paths = [\n",
    "    JoinPath(\"player\", \"team\", \"team\", \"team_name\"),\n",
    "    JoinPath(\"team\", \"city\", \"location\", \"city_name\"),\n",
    "    JoinPath(\"team\", \"manager\", \"ownership\", \"name\"),\n",
    "    JoinPath(\"manager\", \"team\", \"nba_team\", \"team_name\"),\n",
    "]\n",
    "\n",
    "# Create join graph\n",
    "player_join_graph = JoinGraph(player_tables, player_join_paths)\n",
    "\n",
    "print(\"âœ… Player Join Graph initialized\")\n",
    "print(f\"   Tables: {list(player_tables.keys())}\")\n",
    "print(f\"   Join Paths:\")\n",
    "for jp in player_join_paths:\n",
    "    print(f\"      {jp.left_table}.{jp.left_key} = {jp.right_table}.{jp.right_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13ef1ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GENERATING BINARY JOIN QUERIES\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Join: player âŸ• team\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. SELECT team.championships, team.location, player.age, player.olympic_gold_medals FROM player JOIN team ON player.team = team.team_name;\n",
      "  2. SELECT team.founded_year, team.team_name, player.name, player.team FROM player JOIN team ON player.team = team.team_name;\n",
      "  ... Generated 10 queries for player âŸ• team\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Join: team âŸ• city\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. SELECT city.city_name, city.population, team.founded_year, team.location FROM team JOIN city ON team.location = city.city_name;\n",
      "  2. SELECT city.state_name, city.area, team.founded_year, team.championships FROM team JOIN city ON team.location = city.city_name;\n",
      "  ... Generated 10 queries for team âŸ• city\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Join: team âŸ• manager\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. SELECT manager.NBA_team, team.location, team.founded_year, manager.name FROM team JOIN manager ON team.ownership = manager.name;\n",
      "  2. SELECT manager.name, manager.own_year, team.team_name, team.founded_year FROM team JOIN manager ON team.ownership = manager.name;\n",
      "  ... Generated 10 queries for team âŸ• manager\n",
      "\n",
      "======================================================================\n",
      "GENERATING MULTI-TABLE JOIN QUERIES\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Join: player âŸ• team âŸ• city\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. SELECT player.fiba_world_cup, player.name, team.team_name, team.ownership, city.state_name FROM player JOIN team ON player.team = team.team_name JOIN city ON team.location = city.city_name;\n",
      "  2. SELECT city.state_name, player.name, player.college, team.founded_year, team.team_name FROM player JOIN team ON player.team = team.team_name JOIN city ON team.location = city.city_name;\n",
      "  ... Generated 10 queries for player âŸ• team âŸ• city\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Join: player âŸ• team âŸ• manager\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. SELECT manager.name, team.founded_year, team.location, manager.age, player.nationality FROM player JOIN team ON player.team = team.team_name JOIN manager ON team.ownership = manager.name;\n",
      "  2. SELECT player.college, manager.name, player.position, team.championships, player.fiba_world_cup FROM player JOIN team ON player.team = team.team_name JOIN manager ON team.ownership = manager.name;\n",
      "  ... Generated 10 queries for player âŸ• team âŸ• manager\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Join: team âŸ• city âŸ• manager\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. SELECT city.population, team.ownership, manager.age, city.gdp, manager.name FROM team JOIN manager ON team.ownership = manager.name JOIN city ON team.location = city.city_name;\n",
      "  2. SELECT manager.NBA_team, city.area, city.city_name, team.team_name, city.population FROM team JOIN manager ON team.ownership = manager.name JOIN city ON team.location = city.city_name;\n",
      "  ... Generated 10 queries for team âŸ• city âŸ• manager\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Join: player âŸ• team âŸ• city âŸ• manager\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. SELECT city.state_name, player.olympic_gold_medals, team.team_name, player.college, manager.own_year FROM player JOIN team ON player.team = team.team_name JOIN manager ON team.ownership = manager.name JOIN city ON team.location = city.city_name;\n",
      "  2. SELECT team.championships, manager.nationality, city.population, player.nationality, player.college FROM player JOIN team ON player.team = team.team_name JOIN manager ON team.ownership = manager.name JOIN city ON team.location = city.city_name;\n",
      "  ... Generated 10 queries for player âŸ• team âŸ• city âŸ• manager\n",
      "\n",
      "======================================================================\n",
      "SAVING QUERIES\n",
      "======================================================================\n",
      "âœ… Saved 70 queries to /data/dengqiyan/UDA-Bench/Query/Player/join_queries.json\n",
      "âœ… Saved 70 queries to /data/dengqiyan/UDA-Bench/Query/Player/join_queries.sql\n",
      "\n",
      "ðŸ“Š Summary:\n",
      "   Total queries generated: 70\n",
      "   Binary joins: 30\n",
      "   Multi-table joins: 40\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Generate JOIN Queries and Save to Player Directory\n",
    "# =============================================================================\n",
    "\n",
    "all_join_queries = []\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. Binary Join Queries (2 tables)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"=\" * 70)\n",
    "print(\"GENERATING BINARY JOIN QUERIES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "binary_join_pairs = [\n",
    "    (\"player\", \"team\"),\n",
    "    (\"team\", \"city\"),\n",
    "    (\"team\", \"manager\"),\n",
    "]\n",
    "\n",
    "for t1, t2 in binary_join_pairs:\n",
    "    print(f\"\\n{'â”€' * 70}\")\n",
    "    print(f\"Join: {t1} âŸ• {t2}\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    \n",
    "    # Generate 10 queries per join pair\n",
    "    for i in range(10):\n",
    "        query, meta = generate_binary_join_query(\n",
    "            player_join_graph,\n",
    "            t1, t2,\n",
    "            select_attr_num=4,\n",
    "            seed=i * 100 + hash(t1 + t2) % 1000\n",
    "        )\n",
    "        \n",
    "        all_join_queries.append({\n",
    "            \"sql\": query,\n",
    "            \"metadata\": meta\n",
    "        })\n",
    "        \n",
    "        if i < 2:  # Print first 2 examples\n",
    "            print(f\"  {i+1}. {query}\")\n",
    "    \n",
    "    print(f\"  ... Generated 10 queries for {t1} âŸ• {t2}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. Multi-Table Join Queries (3+ tables)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(\"GENERATING MULTI-TABLE JOIN QUERIES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "multi_join_combinations = [\n",
    "    [\"player\", \"team\", \"city\"],\n",
    "    [\"player\", \"team\", \"manager\"],\n",
    "    [\"team\", \"city\", \"manager\"],\n",
    "    [\"player\", \"team\", \"city\", \"manager\"],  # 4-table join\n",
    "]\n",
    "\n",
    "for tables in multi_join_combinations:\n",
    "    print(f\"\\n{'â”€' * 70}\")\n",
    "    print(f\"Join: {' âŸ• '.join(tables)}\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    \n",
    "    # Generate 10 queries per combination\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            query, meta = generate_multi_table_join_query(\n",
    "                player_join_graph,\n",
    "                tables,\n",
    "                select_attr_num=5,\n",
    "                seed=i * 200 + hash(str(tables)) % 1000\n",
    "            )\n",
    "            \n",
    "            all_join_queries.append({\n",
    "                \"sql\": query,\n",
    "                \"metadata\": meta\n",
    "            })\n",
    "            \n",
    "            if i < 2:  # Print first 2 examples\n",
    "                print(f\"  {i+1}. {query}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ Error: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"  ... Generated 10 queries for {' âŸ• '.join(tables)}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. Save Queries to Files\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(\"SAVING QUERIES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "output_dir = \"/data/dengqiyan/UDA-Bench/Query/Player\"\n",
    "\n",
    "# Save as JSON\n",
    "save_queries_to_file(\n",
    "    all_join_queries,\n",
    "    f\"{output_dir}/join_queries.json\",\n",
    "    format=\"json\"\n",
    ")\n",
    "\n",
    "# Save as SQL file\n",
    "save_queries_to_file(\n",
    "    all_join_queries,\n",
    "    f\"{output_dir}/join_queries.sql\",\n",
    "    format=\"sql\"\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nðŸ“Š Summary:\")\n",
    "print(f\"   Total queries generated: {len(all_join_queries)}\")\n",
    "binary_count = sum(1 for q in all_join_queries if q['metadata']['subcategory'] == 'binary_join')\n",
    "multi_count = sum(1 for q in all_join_queries if q['metadata']['subcategory'] == 'multi_table_join')\n",
    "print(f\"   Binary joins: {binary_count}\")\n",
    "print(f\"   Multi-table joins: {multi_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
